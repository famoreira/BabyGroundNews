{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b2894a-68ba-437c-9de1-539db952867d",
   "metadata": {},
   "source": [
    "# Baby Ground News"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57763db-bc45-4e18-a104-49d2f450e84e",
   "metadata": {},
   "source": [
    "## Brave Search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3f8c3d3-3d48-4561-a531-4b00f13c5f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRAVE_TOKEN = \"USE_YOUR_KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39a13f7-948f-41fe-b039-0cf7fa491733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# --------------------\n",
    "# Search Parameters\n",
    "# --------------------\n",
    "\n",
    "geography = \"Greenland\"\n",
    "topic = \"NATO and sovereignty\"\n",
    "\n",
    "allowed_domains = [\n",
    "    \"www.democracynow.org\",\n",
    "    \"jacobin.com\",\n",
    "    \"theintercept.com\",\n",
    "    \"www.haaretz.com\",\n",
    "    \"www.theguardian.com\",\n",
    "    \"www.france24.com/en\",\n",
    "    \"www.aljazeera.com\",\n",
    "    \"www.npr.org\",\n",
    "    \"www.sueddeutsche.de\",\n",
    "    \"english.elpais.com\",\n",
    "    \"www.abc.net.au/news\",\n",
    "    \"www.asahi.com/ajw/\",\n",
    "    \"www.blick.ch\",\n",
    "    \"www.dailymaverick.co.za\",\n",
    "    \"www.dawn.com\",\n",
    "    \"www.spiegel.de/international\",\n",
    "    \"www.repubblica.it\",\n",
    "    \"www.lemonde.fr/en\",\n",
    "    \"www.bbc.com/news\",\n",
    "    \"www.cbc.ca/news\",\n",
    "    \"www.reuters.com\",\n",
    "    \"apnews.com\",\n",
    "    \"africtelegraph.com\",\n",
    "    \"www.ansa.it/english\",\n",
    "    \"balkaninsight.com\",\n",
    "    \"www.correiobraziliense.com.br\",\n",
    "    \"www.euronews.com\",\n",
    "    \"www.hindustantimes.com\",\n",
    "    \"www.straitstimes.com\",\n",
    "    \"www.scmp.com\",\n",
    "    \"www.channelnewsasia.com\",\n",
    "    \"dnevnik.mk\",\n",
    "    \"www.thetimes.co.uk\",\n",
    "    \"www.wsj.com\",\n",
    "    \"www.jpost.com\",\n",
    "    \"www.theglobeandmail.com\",\n",
    "    \"www.afr.com\",\n",
    "    \"www.businesslive.co.za\",\n",
    "    \"www.faz.net\",\n",
    "    \"gulfnews.com\",\n",
    "    \"www.indiatoday.in\",\n",
    "    \"www.telegraph.co.uk\",\n",
    "    \"www.dailymail.co.uk\",\n",
    "    \"www.trtworld.com\",\n",
    "    \"www.lefigaro.fr\",\n",
    "    \"www.lanacion.com.ar\",\n",
    "    \"www.foxnews.com\",\n",
    "    \"tass.com\",\n",
    "    \"www.rt.com\",\n",
    "    \"www.globaltimes.cn\",\n",
    "    \"www.xinhuanet.com/english\"\n",
    "]\n",
    "\n",
    "BASE_URL = \"https://api.search.brave.com/res/v1/news/search\"\n",
    "\n",
    "base_params = {\n",
    "    \"search_lang\": \"en\",\n",
    "    \"ui_lang\": \"en-US\",\n",
    "    \"country\": \"US\",\n",
    "    \"safesearch\": \"strict\",\n",
    "    \"spellcheck\": True,\n",
    "    \"freshness\": \"py\",\n",
    "    \"operators\": True,\n",
    "    \"count\": 50,\n",
    "    \"offset\": 0,\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Accept-Encoding\": \"gzip\",\n",
    "    \"X-Subscription-Token\": BRAVE_TOKEN,\n",
    "}\n",
    "\n",
    "# --------------------\n",
    "# Rate limit + retry/backoff\n",
    "# --------------------\n",
    "\n",
    "MIN_SECONDS_BETWEEN_CALLS = 1.35\n",
    "TIMEOUT_SECONDS = 15\n",
    "MAX_RETRIES_429 = 3\n",
    "\n",
    "_last_call_time = 0.0\n",
    "\n",
    "def brave_get(session: requests.Session, params: dict) -> requests.Response:\n",
    "    global _last_call_time\n",
    "\n",
    "    for attempt in range(MAX_RETRIES_429 + 1):\n",
    "        now = time.monotonic()\n",
    "        wait = MIN_SECONDS_BETWEEN_CALLS - (now - _last_call_time)\n",
    "        if wait > 0:\n",
    "            time.sleep(wait)\n",
    "\n",
    "        resp = session.get(BASE_URL, params=params, timeout=TIMEOUT_SECONDS)\n",
    "        _last_call_time = time.monotonic()\n",
    "\n",
    "        if resp.status_code != 429:\n",
    "            return resp\n",
    "\n",
    "        retry_after = resp.headers.get(\"Retry-After\")\n",
    "        if retry_after:\n",
    "            try:\n",
    "                backoff = float(retry_after)\n",
    "            except ValueError:\n",
    "                backoff = 2.0\n",
    "        else:\n",
    "            backoff = 2.0 + 2.0 * attempt\n",
    "\n",
    "        time.sleep(backoff)\n",
    "\n",
    "    return resp\n",
    "\n",
    "# --------------------\n",
    "# Search and Collect\n",
    "# --------------------\n",
    "\n",
    "rows = []\n",
    "error_log = []\n",
    "\n",
    "MAX_PAGES = 10\n",
    "\n",
    "session = requests.Session()\n",
    "session.headers.update(headers)\n",
    "\n",
    "for domain in allowed_domains:\n",
    "    # print(f\"\\n Searching in: {domain}\")\n",
    "    domain_query = f\"{geography} {topic} site:{domain}\"\n",
    "\n",
    "    for page in range(MAX_PAGES):\n",
    "        params = base_params.copy()\n",
    "        params[\"q\"] = domain_query\n",
    "        params[\"offset\"] = page\n",
    "\n",
    "        # print(f\"  → page {page+1}/{MAX_PAGES}\", flush=True)\n",
    "\n",
    "        try:\n",
    "            resp = brave_get(session, params=params)\n",
    "\n",
    "            if resp.status_code != 200:\n",
    "                error_log.append({\n",
    "                    \"domain\": domain,\n",
    "                    \"page\": page,\n",
    "                    \"error\": f\"HTTP {resp.status_code}: {resp.text[:200]}\"\n",
    "                })\n",
    "                if resp.status_code == 429:\n",
    "                    break\n",
    "                continue\n",
    "\n",
    "            data = resp.json()\n",
    "\n",
    "        except Exception as e:\n",
    "            error_log.append({\"domain\": domain, \"page\": page, \"error\": str(e)})\n",
    "            continue\n",
    "\n",
    "        results = data.get(\"results\", [])\n",
    "        if not results:\n",
    "            error_log.append({\"domain\": domain, \"page\": page, \"error\": \"No results\"})\n",
    "            break\n",
    "\n",
    "        for item in results:\n",
    "            rows.append({\n",
    "                \"Brave page_age\": item.get(\"page_age\") or item.get(\"age\") or \"\",\n",
    "                \"Description\": item.get(\"title\") or \"\",\n",
    "                \"Snippet\": item.get(\"description\") or \"\",\n",
    "                \"Hyperlink\": item.get(\"url\") or \"\",\n",
    "                \"Source Domain\": (item.get(\"meta_url\") or {}).get(\"hostname\") or \"\",\n",
    "            })\n",
    "\n",
    "# --------------------\n",
    "# Build DataFrame\n",
    "# --------------------\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "if not df.empty:\n",
    "    df.drop_duplicates(subset=[\"Hyperlink\"], inplace=True)\n",
    "\n",
    "# --------------------\n",
    "# CSV export\n",
    "# --------------------\n",
    "\n",
    "# today_str = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "# query_slug = f\"{topic}_{geography}\".replace(\" \", \"_\")\n",
    "# filename = f\"news_{query_slug}_{today_str}.csv\"\n",
    "# df.to_csv(filename, index=False)\n",
    "\n",
    "# if error_log:\n",
    "#     err_df = pd.DataFrame(error_log)\n",
    "#     err_filename = f\"errors_{query_slug}_{today_str}.csv\"\n",
    "#     err_df.to_csv(err_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29f296b-fbfe-4fc5-ab11-84eb4e89ceff",
   "metadata": {},
   "source": [
    "## Sentiment classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e97dcb6-6db9-4b6e-b7af-3ad95e8fcaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\famor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "import nltk\n",
    "nltk.download(\"vader_lexicon\")\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Parse Brave page_age into a datetime\n",
    "# ----------------------------\n",
    "\n",
    "REL_RE = re.compile(r\"^\\s*(\\d+)\\s+(minute|hour|day|week|month|year)s?\\s+ago\\s*$\", re.I)\n",
    "\n",
    "def parse_brave_page_age(val):\n",
    "    if pd.isna(val):\n",
    "        return pd.NaT\n",
    "    s = str(val).strip()\n",
    "    if not s:\n",
    "        return pd.NaT\n",
    "\n",
    "    # 1) ISO-ish cases\n",
    "    try:\n",
    "        s_iso = s.replace(\"Z\", \"+00:00\") if s.endswith(\"Z\") else s\n",
    "        dt = datetime.fromisoformat(s_iso)\n",
    "        if dt.tzinfo is None:\n",
    "            dt = dt.replace(tzinfo=timezone.utc)\n",
    "        return pd.Timestamp(dt.astimezone(timezone.utc))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) Relative cases like \"3 weeks ago\"\n",
    "    m = REL_RE.match(s.lower())\n",
    "    if m:\n",
    "        amount = int(m.group(1))\n",
    "        unit = m.group(2).lower()\n",
    "        delta = {\n",
    "            \"minute\": timedelta(minutes=amount),\n",
    "            \"hour\": timedelta(hours=amount),\n",
    "            \"day\": timedelta(days=amount),\n",
    "            \"week\": timedelta(weeks=amount),\n",
    "            \"month\": timedelta(days=30 * amount),   # approx\n",
    "            \"year\": timedelta(days=365 * amount),   # approx\n",
    "        }[unit]\n",
    "        return pd.Timestamp(datetime.now(timezone.utc) - delta)\n",
    "\n",
    "    # 3) Common short date formats\n",
    "    for fmt in (\"%d-%b-%y\", \"%d-%b-%Y\", \"%Y-%m-%d\"):\n",
    "        try:\n",
    "            dt = datetime.strptime(s, fmt).replace(tzinfo=timezone.utc)\n",
    "            return pd.Timestamp(dt)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    return pd.NaT\n",
    "\n",
    "df[\"ArticleDateUTC\"] = df[\"Brave page_age\"].apply(parse_brave_page_age)\n",
    "\n",
    "# Sort most recent first\n",
    "df = df.sort_values(\"ArticleDateUTC\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Add a recency weight (newer = higher)\n",
    "# ----------------------------\n",
    "HALF_LIFE_DAYS = 14\n",
    "\n",
    "now_utc = pd.Timestamp(datetime.now(timezone.utc))\n",
    "age_days = (now_utc - df[\"ArticleDateUTC\"]).dt.total_seconds() / (24 * 3600)\n",
    "\n",
    "df[\"AgeDays\"] = age_days\n",
    "df[\"RecencyWeight\"] = df[\"AgeDays\"].apply(\n",
    "    lambda d: float(\"nan\") if pd.isna(d) else (0.5 ** (d / HALF_LIFE_DAYS))\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Outlet classification table\n",
    "# ----------------------------\n",
    "outlets = [\n",
    "    (\"Democracy Now!\", \"US\", \"www.democracynow.org\", \"Far Left\", -5, \"Activist framing, anti-capitalist, anti-imperialist\"),\n",
    "    (\"Jacobin\", \"US\", \"jacobin.com\", \"Far Left\", -5, \"Openly socialist, labor-focused, anti-neoliberal\"),\n",
    "    (\"The Intercept\", \"US\", \"theintercept.com\", \"Far Left\", -5, \"Investigative, adversarial to intelligence/military\"),\n",
    "    (\"Haaretz\", \"Israel\", \"www.haaretz.com\", \"Left\", -3, \"Pro-peace, civil rights framing, critical of Israeli right-wing government\"),\n",
    "    (\"The Guardian\", \"UK\", \"www.theguardian.com\", \"Left\", -3, \"Social justice, progressive framing\"),\n",
    "    (\"France 24\", \"France\", \"www.france24.com/en\", \"Center Left\", -2, \"Slight progressive lean, EU integrationist\"),\n",
    "    (\"Al Jazeera\", \"Qatar\", \"www.aljazeera.com\", \"Center Left\", -2, \"Pro-Global South, critical of U.S. foreign policy\"),\n",
    "    (\"NPR\", \"US\", \"www.npr.org\", \"Center Left\", -2, \"Balanced tone, liberal cultural framing\"),\n",
    "    (\"Süddeutsche Zeitung\", \"Germany\", \"www.sueddeutsche.de\", \"Center Left\", -2, \"Liberal democratic, pro-EU, socially progressive\"),\n",
    "    (\"El Pais\", \"Spain\", \"english.elpais.com\", \"Center Left\", -2, \"Pro-EU, social democracy framing\"),\n",
    "    (\"ABC News\", \"Australia\", \"www.abc.net.au/news\", \"Center Left\", -2, \"Public broadcaster; slight progressive tone\"),\n",
    "    (\"Asahi Shimbun\", \"Japan\", \"www.asahi.com/ajw/\", \"Center Left\", -2, \"Liberal, pro-democracy, anti-militarism framing\"),\n",
    "    (\"Blick\", \"Switzerland\", \"www.blick.ch\", \"Center Left\", -2, \"Tabloid with progressive social framing\"),\n",
    "    (\"Daily Maverick\", \"South Africa\", \"www.dailymaverick.co.za\", \"Center Left\", -2, \"Investigative, anti-corruption, liberal democratic lean\"),\n",
    "    (\"Dawn\", \"Pakistan\", \"www.dawn.com\", \"Center Left\", -2, \"Independent, secular framing\"),\n",
    "    (\"Der Spiegel\", \"Germany\", \"www.spiegel.de/international\", \"Center Left\", -2, \"Investigative, pro-EU, liberal framing\"),\n",
    "    (\"La Repubblica\", \"Italy\", \"www.repubblica.it\", \"Center Left\", -2, \"Progressive editorial line, pro-EU\"),\n",
    "    (\"Le Monde\", \"France\", \"www.lemonde.fr/en\", \"Center Left\", -2, \"Mainstream liberal paper, intellectual tone\"),\n",
    "    (\"BBC News\", \"UK\", \"www.bbc.com/news\", \"Center\", 0, \"Traditional neutrality, Western liberal framing\"),\n",
    "    (\"CBC News\", \"Canada\", \"www.cbc.ca/news\", \"Center\", 0, \"Public broadcaster with balanced coverage\"),\n",
    "    (\"Reuters\", \"Global\", \"www.reuters.com\", \"Center\", 0, \"Fact-based, highly neutral tone\"),\n",
    "    (\"Associated Press (AP)\", \"US\", \"apnews.com\", \"Center\", 0, \"Minimal framing, trusted wire service\"),\n",
    "    (\"AfricTelegraph\", \"Pan-African\", \"africtelegraph.com\", \"Center\", 0, \"Covers African perspectives, moderate framing\"),\n",
    "    (\"ANSA\", \"Italy\", \"www.ansa.it/english\", \"Center\", 0, \"Italy's main wire service; neutral tone\"),\n",
    "    (\"Balkan Insight\", \"Southeast Europe\", \"balkaninsight.com\", \"Center\", 0, \"Regional watchdog reporting\"),\n",
    "    (\"Correio Braziliense\", \"Brazil\", \"www.correiobraziliense.com.br\", \"Center\", 0, \"One of Brazil's oldest papers, centrist framing\"),\n",
    "    (\"Euronews\", \"Europe\", \"www.euronews.com\", \"Center\", 0, \"Multilingual outlet; attempts neutral framing\"),\n",
    "    (\"Hindustan Times\", \"India\", \"www.hindustantimes.com\", \"Center\", 0, \"Balanced framing, mainstream outlet\"),\n",
    "    (\"Straits Times\", \"Singapore\", \"www.straitstimes.com\", \"Center\", 0, \"Government-aligned, factual, cautious framing\"),\n",
    "    (\"South China Morning Post\", \"Hong Kong\", \"www.scmp.com\", \"Center Right\", 2, \"Pro-business, increasingly aligned with Beijing\"),\n",
    "    (\"Channel News Asia\", \"Singapore\", \"www.channelnewsasia.com\", \"Center Right\", 2, \"Neutral framing with state alignment\"),\n",
    "    (\"Dnevnik\", \"North Macedonia\", \"dnevnik.mk\", \"Center Right\", 2, \"National political coverage with conservative tone\"),\n",
    "    (\"The Time\", \"UK\", \"www.thetimes.co.uk\", \"Center Right\", 2, \"Conservative but traditional framing\"),\n",
    "    (\"Wall Street Journal\", \"US\", \"www.wsj.com\", \"Center Right\", 2, \"Pro-market economic framing\"),\n",
    "    (\"The Jerusalem Post\", \"Israel\", \"www.jpost.com\", \"Center Right\", 2, \"Pro-Israel security framing\"),\n",
    "    (\"The Globe and Mail\", \"Canada\", \"www.theglobeandmail.com\", \"Center Right\", 2, \"Fiscal conservative editorial tone\"),\n",
    "    (\"Australian Financial Review\", \"Australia\", \"www.afr.com\", \"Center Right\", 2, \"Business-first framing\"),\n",
    "    (\"Business Day\", \"South Africa\", \"www.businesslive.co.za\", \"Center Right\", 2, \"Fiscally conservative, business-focused\"),\n",
    "    (\"Frankfurter Allgemeine (FAZ)\", \"Germany\", \"www.faz.net\", \"Center Right\", 2, \"Conservative-liberal, pro-business\"),\n",
    "    (\"Gulf News\", \"UAE\", \"gulfnews.com\", \"Center Right\", 2, \"Pro-establishment, business-heavy coverage\"),\n",
    "    (\"India Today\", \"India\", \"www.indiatoday.in\", \"Right\", 3, \"Nationalistic editorial tone\"),\n",
    "    (\"The Telegraph\", \"UK\", \"www.telegraph.co.uk\", \"Right\", 3, \"Conservative Party aligned, pro-Brexit\"),\n",
    "    (\"Daily Mail\", \"UK\", \"www.dailymail.co.uk\", \"Right\", 3, \"Populist conservative framing\"),\n",
    "    (\"TRT World\", \"Turkey\", \"www.trtworld.com\", \"Far Right\", 5, \"State-aligned, Islamist conservative lean\"),\n",
    "    (\"Le Figaro\", \"France\", \"www.lefigaro.fr\", \"Right\", 3, \"Traditional conservative, pro-business\"),\n",
    "    (\"La Nacion\", \"Argentina\", \"www.lanacion.com.ar\", \"Right\", 3, \"Pro-business, critical of leftist governments\"),\n",
    "    (\"Fox News\", \"US\", \"www.foxnews.com\", \"Far Right\", 5, \"Right-wing framing, especially in opinion\"),\n",
    "    (\"TASS\", \"Russia\", \"tass.com\", \"Far Right\", 5, \"Pro-Kremlin, nationalist framing\"),\n",
    "    (\"RT (Russia Today)\", \"Russia\", \"www.rt.com\", \"Far Right\", 5, \"Anti-Western framing, conspiratorial\"),\n",
    "    (\"Global Times\", \"China\", \"www.globaltimes.cn\", \"Far Right\", 5, \"Nationalist, anti-Western, CCP-aligned\"),\n",
    "    (\"Xinhua\", \"China\", \"www.xinhuanet.com/english\", \"Far Right\", 5, \"Pro-CCP propaganda framing\"),\n",
    "]\n",
    "\n",
    "outlet_df = pd.DataFrame(outlets, columns=[\"Outlet\", \"Country/Region\", \"URL\", \"Political Leaning\", \"Score\", \"Notes\"])\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Match Source Domain -> outlet table (exact + fuzzy)\n",
    "# ----------------------------\n",
    "def normalize_domain(s):\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    s = str(s).strip().lower()\n",
    "    s = s.replace(\"https://\", \"\").replace(\"http://\", \"\")\n",
    "    s = s.split(\"/\")[0]\n",
    "    return s\n",
    "\n",
    "df[\"SourceDomainNorm\"] = df[\"Source Domain\"].apply(normalize_domain)\n",
    "outlet_df[\"URLNorm\"] = outlet_df[\"URL\"].apply(normalize_domain)\n",
    "\n",
    "merged = df.merge(\n",
    "    outlet_df,\n",
    "    how=\"left\",\n",
    "    left_on=\"SourceDomainNorm\",\n",
    "    right_on=\"URLNorm\",\n",
    "    suffixes=(\"\", \"_outlet\")\n",
    ")\n",
    "\n",
    "# Fuzzy match only where missing (optional)\n",
    "try:\n",
    "    from rapidfuzz import process, fuzz\n",
    "    url_choices = outlet_df[\"URLNorm\"].tolist()\n",
    "\n",
    "    def fuzzy_pick(domain):\n",
    "        if not domain:\n",
    "            return None\n",
    "        match = process.extractOne(domain, url_choices, scorer=fuzz.ratio)\n",
    "        if match and match[1] >= 85:\n",
    "            return match[0]\n",
    "        return None\n",
    "\n",
    "    missing = merged[\"Political Leaning\"].isna()\n",
    "    merged.loc[missing, \"URLNorm\"] = merged.loc[missing, \"SourceDomainNorm\"].apply(fuzzy_pick)\n",
    "\n",
    "    merged = merged.drop(columns=[\"Outlet\", \"Country/Region\", \"URL\", \"Political Leaning\", \"Score\", \"Notes\"], errors=\"ignore\")\n",
    "    merged = merged.merge(\n",
    "        outlet_df[[\"URLNorm\", \"Outlet\", \"Country/Region\", \"URL\", \"Political Leaning\", \"Score\", \"Notes\"]],\n",
    "        how=\"left\",\n",
    "        on=\"URLNorm\"\n",
    "    )\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Sentiment / vibes on Snippet: -1..1\n",
    "# ----------------------------\n",
    "try:\n",
    "    import nltk\n",
    "    from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "    vader_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    def snippet_sentiment(snippet: str) -> float:\n",
    "        if not isinstance(snippet, str) or not snippet.strip():\n",
    "            return 0.0\n",
    "        return vader_analyzer.polarity_scores(snippet)[\"compound\"]\n",
    "\n",
    "    USE_VADER = True\n",
    "except Exception:\n",
    "    USE_VADER = False\n",
    "\n",
    "POS_WORDS = {\"good\",\"great\",\"positive\",\"benefit\",\"improve\",\"success\",\"win\",\"peace\",\"deal\",\"growth\",\"safe\"}\n",
    "NEG_WORDS = {\"bad\",\"worse\",\"negative\",\"risk\",\"crisis\",\"war\",\"threat\",\"fail\",\"loss\",\"danger\",\"probe\",\"leak\",\"tensions\",\"cancel\"}\n",
    "\n",
    "def sentiment_fallback(snippet: str) -> float:\n",
    "    if not isinstance(snippet, str) or not snippet.strip():\n",
    "        return 0.0\n",
    "    words = re.findall(r\"[a-z']+\", snippet.lower())\n",
    "    if not words:\n",
    "        return 0.0\n",
    "    pos = sum(1 for w in words if w in POS_WORDS)\n",
    "    neg = sum(1 for w in words if w in NEG_WORDS)\n",
    "    score = (pos - neg) / max(1, pos + neg)\n",
    "    return max(-1.0, min(1.0, float(score)))\n",
    "\n",
    "if USE_VADER:\n",
    "    merged[\"SnippetSentiment\"] = merged[\"Snippet\"].fillna(\"\").astype(str).apply(snippet_sentiment)\n",
    "else:\n",
    "    merged[\"SnippetSentiment\"] = merged[\"Snippet\"].fillna(\"\").astype(str).apply(sentiment_fallback)\n",
    "\n",
    "merged[\"WeightedSentiment\"] = merged[\"SnippetSentiment\"] * merged[\"RecencyWeight\"]\n",
    "\n",
    "# ----------------------------\n",
    "# 7) Keep / output what you want\n",
    "# ----------------------------\n",
    "# OUTPUT_CSV = \"classified_weighted_news.csv\"\n",
    "COLUMNS_TO_DROP = [\"SourceDomainNorm\", \"URLNorm\", \"Outlet\", \"URL\"]\n",
    "\n",
    "final_df = merged.drop(columns=COLUMNS_TO_DROP, errors=\"ignore\")\n",
    "\n",
    "# ----------------------------\n",
    "# CSV export\n",
    "# ----------------------------\n",
    "# final_df.to_csv(OUTPUT_CSV, index=False)\n",
    "# print(f\" Saved classified + weighted output to: {OUTPUT_CSV}\")\n",
    "\n",
    "# print(merged[[\n",
    "#     \"ArticleDateUTC\", \"Brave page_age\", \"Description\", \"Snippet\", \"Hyperlink\", \"Source Domain\",\n",
    "#     \"Outlet\", \"Political Leaning\", \"Score\",\n",
    "#     \"SnippetSentiment\", \"RecencyWeight\", \"WeightedSentiment\"\n",
    "# ]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0b4fd2-d166-430e-8a6e-81dda60fa36a",
   "metadata": {},
   "source": [
    "## LLM Summary Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9ed8944-3818-45ad-a95b-faa550c2bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. Azure OpenAI configuration\n",
    "# -----------------------------\n",
    "openai_api_version = \"API_VERSION\"\n",
    "openai_api_key = \"USE_YOUR_KEY\"\n",
    "openai_api_base = \"https://xtz.openai.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9bed02c-2344-4766-b595-e6387911c453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_ts_utc</th>\n",
       "      <th>time_window</th>\n",
       "      <th>rows_used</th>\n",
       "      <th>topic</th>\n",
       "      <th>summary</th>\n",
       "      <th>key_developments</th>\n",
       "      <th>timeline</th>\n",
       "      <th>open_questions</th>\n",
       "      <th>elapsed_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-02-06T20:56:41.644906+00:00</td>\n",
       "      <td>last 7 days (AgeDays &lt; 7)</td>\n",
       "      <td>75</td>\n",
       "      <td>NATO and Arctic Strategy Amid US-Greenland Ten...</td>\n",
       "      <td>Recent developments have highlighted tensions ...</td>\n",
       "      <td>[\"Canada and France opened consulates in Green...</td>\n",
       "      <td>[\"Canada and France open consulates in Greenla...</td>\n",
       "      <td>[\"How will NATO's Arctic strategy evolve in re...</td>\n",
       "      <td>68.539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         run_ts_utc                time_window  rows_used  \\\n",
       "0  2026-02-06T20:56:41.644906+00:00  last 7 days (AgeDays < 7)         75   \n",
       "\n",
       "                                               topic  \\\n",
       "0  NATO and Arctic Strategy Amid US-Greenland Ten...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Recent developments have highlighted tensions ...   \n",
       "\n",
       "                                    key_developments  \\\n",
       "0  [\"Canada and France opened consulates in Green...   \n",
       "\n",
       "                                            timeline  \\\n",
       "0  [\"Canada and France open consulates in Greenla...   \n",
       "\n",
       "                                      open_questions  elapsed_time  \n",
       "0  [\"How will NATO's Arctic strategy evolve in re...        68.539  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# ------------------------------------------\n",
    "# 0) Client\n",
    "# ------------------------------------------\n",
    "client = AzureOpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    api_version=openai_api_version,\n",
    "    azure_endpoint=openai_api_base\n",
    ")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 1) Uses DataFrame from previous cell\n",
    "# ------------------------------------------\n",
    "df = final_df.copy()\n",
    "\n",
    "# ------------------------------------------\n",
    "# 2) Filter last 7 days using AgeDays\n",
    "# ------------------------------------------\n",
    "df[\"AgeDays\"] = pd.to_numeric(df[\"AgeDays\"], errors=\"coerce\")\n",
    "df[\"RecencyWeight\"] = pd.to_numeric(df[\"RecencyWeight\"], errors=\"coerce\")\n",
    "\n",
    "last7 = df[df[\"AgeDays\"].notna() & (df[\"AgeDays\"] < 7)].copy()\n",
    "\n",
    "if last7.empty:\n",
    "    weekly_df = pd.DataFrame([{\n",
    "        \"run_ts_utc\": datetime.now(timezone.utc).isoformat(),\n",
    "        \"time_window\": \"last 7 days (AgeDays < 7)\",\n",
    "        \"rows_used\": 0,\n",
    "        \"topic\": None,\n",
    "        \"summary\": None,\n",
    "        \"key_developments\": \"[]\",\n",
    "        \"timeline\": \"[]\",\n",
    "        \"open_questions\": \"[]\",\n",
    "        \"elapsed_time\": 0.0\n",
    "    }])\n",
    "\n",
    "    # print(weekly_df)\n",
    "    # weekly_df.to_csv(\"weekly_news_summary.csv\", index=False)\n",
    "    raise SystemExit()\n",
    "\n",
    "# ------------------------------------------\n",
    "# 3) Clean text + sort + dedupe\n",
    "# ------------------------------------------\n",
    "for c in [\"Description\", \"Snippet\"]:\n",
    "    if c in last7.columns:\n",
    "        last7[c] = (\n",
    "            last7[c].astype(str)\n",
    "            .str.replace(\"\\u00a0\", \" \", regex=False)\n",
    "            .str.replace(\"Â·\", \"·\", regex=False)\n",
    "            .str.replace(\"â€™\", \"’\", regex=False)\n",
    "            .str.replace(\"â€˜\", \"‘\", regex=False)\n",
    "            .str.replace(\"â€œ\", \"“\", regex=False)\n",
    "            .str.replace(\"â€\", \"”\", regex=False)\n",
    "            .str.replace(\"â€”\", \"—\", regex=False)\n",
    "            .str.replace(\"â†’\", \"→\", regex=False)\n",
    "        )\n",
    "\n",
    "# Prefer high weight + newest (smallest AgeDays)\n",
    "last7 = last7.sort_values([\"RecencyWeight\", \"AgeDays\"], ascending=[False, True])\n",
    "\n",
    "# Drop obvious duplicates (same story/same link)\n",
    "dedupe_cols = [c for c in [\"Hyperlink\", \"Description\"] if c in last7.columns]\n",
    "if dedupe_cols:\n",
    "    last7 = last7.drop_duplicates(subset=dedupe_cols, keep=\"first\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 4) Build JSON \"jobs\"\n",
    "# ------------------------------------------\n",
    "def safe_str(x):\n",
    "    return \"\" if pd.isna(x) else str(x)\n",
    "\n",
    "jobs = []\n",
    "for _, r in last7.iterrows():\n",
    "    jobs.append({\n",
    "        \"AgeDays\": float(r[\"AgeDays\"]) if pd.notna(r[\"AgeDays\"]) else None,\n",
    "        \"RecencyWeight\": float(r[\"RecencyWeight\"]) if pd.notna(r[\"RecencyWeight\"]) else None,\n",
    "        \"ArticleDateUTC\": safe_str(r.get(\"ArticleDateUTC\")),\n",
    "        \"SourceDomain\": safe_str(r.get(\"Source Domain\")),\n",
    "        \"CountryRegion\": safe_str(r.get(\"Country/Region\")),\n",
    "        \"PoliticalLeaning\": safe_str(r.get(\"Political Leaning\")),\n",
    "        \"Description\": safe_str(r.get(\"Description\")),\n",
    "        \"Snippet\": safe_str(r.get(\"Snippet\")),\n",
    "        \"Hyperlink\": safe_str(r.get(\"Hyperlink\")),\n",
    "    })\n",
    "\n",
    "# print(f\" Loaded {len(df)} rows; using {len(jobs)} rows where AgeDays < 7.\")\n",
    "\n",
    "# ------------------------------------------\n",
    "# 5) Chunk + call model (MAP)\n",
    "# ------------------------------------------\n",
    "chunk_size = 30\n",
    "map_chunk_dfs = []\n",
    "\n",
    "system_msg = (\n",
    "    \"You are a news analyst producing a weekly brief for ONE main topic in this dataset. \"\n",
    "    \"Use ONLY the provided context JSON. \"\n",
    "    \"Merge duplicates. Avoid speculation. \"\n",
    "    \"Output must be STRICT JSON only.\"\n",
    ")\n",
    "\n",
    "query = (\n",
    "    \"Summarize the last 7 days of news represented by these rows into a concise weekly brief. \"\n",
    "    \"Identify the main topic, key developments, a simple timeline, and open questions.\"\n",
    ")\n",
    "\n",
    "output_rules = (\n",
    "    \"Return STRICT JSON ONLY with EXACT keys:\\n\"\n",
    "    \"  - topic (string)\\n\"\n",
    "    \"  - key_developments (array of strings)\\n\"\n",
    "    \"  - timeline (array of objects with keys: age_days (number), event (string))\\n\"\n",
    "    \"  - open_questions (array of strings)\\n\"\n",
    "    \"Do not add extra keys.\"\n",
    ")\n",
    "\n",
    "total = len(jobs)\n",
    "start_all = time.time()\n",
    "\n",
    "for i, start_idx in enumerate(range(0, total, chunk_size)):\n",
    "    end_idx = min(start_idx + chunk_size, total)\n",
    "    chunk = jobs[start_idx:end_idx]\n",
    "    context = json.dumps(chunk, ensure_ascii=False)\n",
    "\n",
    "    # print(f\"\\n MAP chunk {i + 1} ({start_idx}–{end_idx})...\")\n",
    "\n",
    "    try:\n",
    "        t0 = time.time()\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            temperature=0.2,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_msg},\n",
    "                {\"role\": \"user\", \"content\": f\"Context JSON:\\n{context}\\n\\nTask:\\n{query}\\n\\n{output_rules}\"},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        raw = resp.choices[0].message.content or \"\"\n",
    "        if not raw.strip():\n",
    "            # print(f\" Skipping MAP chunk {i + 1}: empty response.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            parsed = json.loads(raw)\n",
    "        except json.JSONDecodeError:\n",
    "            s = raw.find(\"{\")\n",
    "            e = raw.rfind(\"}\")\n",
    "            if s == -1 or e == -1 or e <= s:\n",
    "                # print(f\" Skipping MAP chunk {i + 1}: invalid JSON.\")\n",
    "                continue\n",
    "            parsed = json.loads(raw[s:e+1])\n",
    "\n",
    "        df_chunk = pd.DataFrame([{\n",
    "            \"chunk_index\": i + 1,\n",
    "            \"topic\": parsed.get(\"topic\"),\n",
    "            \"key_developments\": json.dumps(parsed.get(\"key_developments\", []), ensure_ascii=False),\n",
    "            \"timeline\": json.dumps(parsed.get(\"timeline\", []), ensure_ascii=False),\n",
    "            \"open_questions\": json.dumps(parsed.get(\"open_questions\", []), ensure_ascii=False),\n",
    "            \"elapsed_time\": time.time() - t0\n",
    "        }])\n",
    "\n",
    "        map_chunk_dfs.append(df_chunk)\n",
    "        # print(f\" MAP chunk {i + 1} done in {df_chunk.loc[0,'elapsed_time']:.2f}s\")\n",
    "\n",
    "    except Exception:\n",
    "        # print(f\" Error in MAP chunk {i + 1}: {e}\")\n",
    "        continue\n",
    "\n",
    "if not map_chunk_dfs:\n",
    "    raise RuntimeError(\"No MAP chunks produced valid output.\")\n",
    "\n",
    "map_df = pd.concat(map_chunk_dfs, ignore_index=True)\n",
    "\n",
    "# ------------------------------------------\n",
    "# 6) REDUCE: combine all chunk summaries\n",
    "# ------------------------------------------\n",
    "reduce_context = map_df.to_dict(orient=\"records\")\n",
    "reduce_context_json = json.dumps(reduce_context, ensure_ascii=False)\n",
    "\n",
    "reduce_system = (\n",
    "    \"You combine multiple partial weekly summaries into ONE final weekly brief. \"\n",
    "    \"Deduplicate, resolve overlaps, avoid speculation. \"\n",
    "    \"Output must be STRICT JSON only.\"\n",
    ")\n",
    "\n",
    "reduce_query = (\n",
    "    \"Combine these chunk-level summaries into one final weekly summary for the topic. \"\n",
    "    \"Keep it concise, but cover the key developments and what remains uncertain.\"\n",
    ")\n",
    "\n",
    "reduce_rules = (\n",
    "    \"Return STRICT JSON ONLY with EXACT keys:\\n\"\n",
    "    \"  - topic (string)\\n\"\n",
    "    \"  - summary (string)\\n\"\n",
    "    \"  - key_developments (array of strings)\\n\"\n",
    "    \"  - timeline (array of strings)\\n\"\n",
    "    \"  - open_questions (array of strings)\\n\"\n",
    "    \"Do not add extra keys.\"\n",
    ")\n",
    "\n",
    "t_reduce = time.time()\n",
    "final_resp = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.2,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": reduce_system},\n",
    "        {\"role\": \"user\", \"content\": f\"Chunk summaries JSON:\\n{reduce_context_json}\\n\\nTask:\\n{reduce_query}\\n\\n{reduce_rules}\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "raw_final = final_resp.choices[0].message.content or \"\"\n",
    "try:\n",
    "    final = json.loads(raw_final)\n",
    "except json.JSONDecodeError:\n",
    "    s = raw_final.find(\"{\")\n",
    "    e = raw_final.rfind(\"}\")\n",
    "    if s == -1 or e == -1 or e <= s:\n",
    "        raise ValueError(\"Final reduce output was not valid JSON.\")\n",
    "    final = json.loads(raw_final[s:e+1])\n",
    "\n",
    "elapsed_total = time.time() - start_all\n",
    "\n",
    "# ------------------------------------------\n",
    "# 7) Build pandas \"table row\"\n",
    "# ------------------------------------------\n",
    "weekly_row = {\n",
    "    \"run_ts_utc\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"time_window\": \"last 7 days (AgeDays < 7)\",\n",
    "    \"rows_used\": int(len(last7)),\n",
    "    \"topic\": final.get(\"topic\"),\n",
    "    \"summary\": final.get(\"summary\"),\n",
    "    \"key_developments\": json.dumps(final.get(\"key_developments\", []), ensure_ascii=False),\n",
    "    \"timeline\": json.dumps(final.get(\"timeline\", []), ensure_ascii=False),\n",
    "    \"open_questions\": json.dumps(final.get(\"open_questions\", []), ensure_ascii=False),\n",
    "    \"elapsed_time\": round(elapsed_total, 3),\n",
    "}\n",
    "\n",
    "weekly_df = pd.DataFrame([weekly_row])\n",
    "\n",
    "# OUT_CSV = \"weekly_news_summary.csv\"\n",
    "# try:\n",
    "#     existing = pd.read_csv(OUT_CSV)\n",
    "#     weekly_df = pd.concat([existing, weekly_df], ignore_index=True)\n",
    "# except FileNotFoundError:\n",
    "#     pass\n",
    "# weekly_df.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "# print(\"\\n Weekly summary table (latest run is last row):\")\n",
    "# print(weekly_df.tail(1))\n",
    "\n",
    "weekly_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf51b6c5-46a7-4c67-9f22-e88044e20966",
   "metadata": {},
   "source": [
    "## News Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59d583ad-0efb-4c05-903d-a4b1f9bcfa83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div style=\"font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial; max-width: 1200px;\">\n",
       "  <div style=\"display:grid; grid-template-columns: 1fr 340px; gap:28px; align-items:start;\">\n",
       "    <div style=\"max-width: 780px;\">\n",
       "      \n",
       "  <div style=\"display:flex; align-items:center; gap:10px; margin-bottom:8px;\">\n",
       "    <span style=\"background:#7f1d1d; color:white; font-weight:700; font-size:12px;\n",
       "                 padding:4px 8px; border-radius:6px;\">\n",
       "      Blindspot\n",
       "    </span>\n",
       "    <span style=\"font-size:12px; color:#4a5568; border:1px solid #e2e8f0; padding:4px 8px; border-radius:999px;\">\n",
       "      75 Sources\n",
       "    </span>\n",
       "  </div>\n",
       "\n",
       "  <div style=\"font-size:32px; font-weight:800; line-height:1.1; margin:6px 0 10px;\">\n",
       "    NATO and Arctic Strategy Amid US-Greenland Tensions\n",
       "  </div>\n",
       "\n",
       "  <div style=\"font-size:16px; color:#2d3748; line-height:1.5; margin-bottom:14px;\">\n",
       "    Recent developments have highlighted tensions between NATO allies and the US over Greenland, with implications for Arctic security and European sovereignty. Canada and France have opened consulates in Greenland to support Denmark, while NATO plans an Arctic Sentry operation to enhance military coherence in the region. Trump's interest in acquiring Greenland has caused friction with Denmark and NATO allies, leading to discussions on NATO's future without US involvement. Russia has expressed readiness to respond to any US weapons deployment in Greenland, adding to geopolitical instability in the Arctic.\n",
       "  </div>\n",
       "\n",
       "  <div style=\"height:14px; border-radius:999px; overflow:hidden; display:flex; border:1px solid #e2e8f0;\">\n",
       "    <div title=\"Far Left 0%\" style=\"width:0%; background:#7f1d1d;\"></div><div title=\"Left 3%\" style=\"width:3%; background:#ef4444;\"></div><div title=\"Center Left 12%\" style=\"width:12%; background:#fca5a5;\"></div><div title=\"Center 55%\" style=\"width:55%; background:#9ca3af;\"></div><div title=\"Center Right 8%\" style=\"width:8%; background:#60a5fa;\"></div><div title=\"Right 5%\" style=\"width:5%; background:#2563eb;\"></div><div title=\"Far Right 17%\" style=\"width:17%; background:#1e3a8a;\"></div>\n",
       "  </div>\n",
       "\n",
       "  <div style=\"display:grid; grid-template-columns: repeat(7, 1fr); gap:6px; margin-top:10px;\">\n",
       "    \n",
       "    <div style=\"color:#7f1d1d; font-weight:700; font-size:12px; text-align:center;\">\n",
       "      Far Left 0%\n",
       "    </div>\n",
       "    \n",
       "    <div style=\"color:#ef4444; font-weight:700; font-size:12px; text-align:center;\">\n",
       "      Left 3%\n",
       "    </div>\n",
       "    \n",
       "    <div style=\"color:#fca5a5; font-weight:700; font-size:12px; text-align:center;\">\n",
       "      Center Left 12%\n",
       "    </div>\n",
       "    \n",
       "    <div style=\"color:#9ca3af; font-weight:700; font-size:12px; text-align:center;\">\n",
       "      Center 55%\n",
       "    </div>\n",
       "    \n",
       "    <div style=\"color:#60a5fa; font-weight:700; font-size:12px; text-align:center;\">\n",
       "      Center Right 8%\n",
       "    </div>\n",
       "    \n",
       "    <div style=\"color:#2563eb; font-weight:700; font-size:12px; text-align:center;\">\n",
       "      Right 5%\n",
       "    </div>\n",
       "    \n",
       "    <div style=\"color:#1e3a8a; font-weight:700; font-size:12px; text-align:center;\">\n",
       "      Far Right 17%\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "\n",
       "  <div style=\"margin-top:10px; font-size:12px; color:#4a5568;\">\n",
       "    Blindspot indicates the least-represented leaning in the last 7 days:\n",
       "    <b style=\"color:#7f1d1d;\">Far Left</b>.\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "    <div>\n",
       "      \n",
       "<div style=\"\n",
       "    border:1px solid #e2e8f0;\n",
       "    border-radius:12px;\n",
       "    padding:14px;\n",
       "    background:#fafafa;\n",
       "    position:sticky; top:12px;\n",
       "\">\n",
       "  <div style=\"font-weight:900; font-size:14px; margin-bottom:8px;\">\n",
       "    Tone by Political Leaning\n",
       "  </div>\n",
       "\n",
       "  <table style=\"width:100%; font-size:12px; border-collapse:collapse;\">\n",
       "    <thead>\n",
       "      <tr style=\"color:#4a5568;\">\n",
       "        <th style=\"text-align:left; padding:6px 10px;\">Leaning</th>\n",
       "        <th style=\"text-align:left; padding:6px 10px;\">Tone</th>\n",
       "      </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "      \n",
       "    <tr>\n",
       "      <td style=\"\n",
       "          padding:6px 10px;\n",
       "          white-space:nowrap;\n",
       "          text-align:left;\n",
       "      \">\n",
       "        <span style=\"\n",
       "          display:inline-block;\n",
       "          width:10px;\n",
       "          height:10px;\n",
       "          border-radius:50%;\n",
       "          background:#7f1d1d;\n",
       "          margin-right:8px;\n",
       "          vertical-align:middle;\n",
       "        \"></span>\n",
       "        <span style=\"vertical-align:middle; font-weight:600;\">\n",
       "          Far Left\n",
       "        </span>\n",
       "      </td>\n",
       "\n",
       "      <td style=\"\n",
       "          padding:6px 10px;\n",
       "          text-align:left;\n",
       "          white-space:nowrap;\n",
       "          color:#2d3748;\n",
       "      \">\n",
       "        --- (No Data)\n",
       "      </td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "      <td style=\"\n",
       "          padding:6px 10px;\n",
       "          white-space:nowrap;\n",
       "          text-align:left;\n",
       "      \">\n",
       "        <span style=\"\n",
       "          display:inline-block;\n",
       "          width:10px;\n",
       "          height:10px;\n",
       "          border-radius:50%;\n",
       "          background:#ef4444;\n",
       "          margin-right:8px;\n",
       "          vertical-align:middle;\n",
       "        \"></span>\n",
       "        <span style=\"vertical-align:middle; font-weight:600;\">\n",
       "          Left\n",
       "        </span>\n",
       "      </td>\n",
       "\n",
       "      <td style=\"\n",
       "          padding:6px 10px;\n",
       "          text-align:left;\n",
       "          white-space:nowrap;\n",
       "          color:#2d3748;\n",
       "      \">\n",
       "        <span style=\"color:#eab308; font-weight:700;\">▲</span> Moderately Positive\n",
       "      </td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "      <td style=\"\n",
       "          padding:6px 10px;\n",
       "          white-space:nowrap;\n",
       "          text-align:left;\n",
       "      \">\n",
       "        <span style=\"\n",
       "          display:inline-block;\n",
       "          width:10px;\n",
       "          height:10px;\n",
       "          border-radius:50%;\n",
       "          background:#fca5a5;\n",
       "          margin-right:8px;\n",
       "          vertical-align:middle;\n",
       "        \"></span>\n",
       "        <span style=\"vertical-align:middle; font-weight:600;\">\n",
       "          Center Left\n",
       "        </span>\n",
       "      </td>\n",
       "\n",
       "      <td style=\"\n",
       "          padding:6px 10px;\n",
       "          text-align:left;\n",
       "          white-space:nowrap;\n",
       "          color:#2d3748;\n",
       "      \">\n",
       "        <span style=\"color:#9ca3af; font-weight:700;font-size:8px; line-height:1;\">▬</span> Neutral\n",
       "      </td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "      <td style=\"\n",
       "          padding:6px 10px;\n",
       "          white-space:nowrap;\n",
       "          text-align:left;\n",
       "      \">\n",
       "        <span style=\"\n",
       "          display:inline-block;\n",
       "          width:10px;\n",
       "          height:10px;\n",
       "          border-radius:50%;\n",
       "          background:#9ca3af;\n",
       "          margin-right:8px;\n",
       "          vertical-align:middle;\n",
       "        \"></span>\n",
       "        <span style=\"vertical-align:middle; font-weight:600;\">\n",
       "          Center\n",
       "        </span>\n",
       "      </td>\n",
       "\n",
       "      <td style=\"\n",
       "          padding:6px 10px;\n",
       "          text-align:left;\n",
       "          white-space:nowrap;\n",
       "          color:#2d3748;\n",
       "      \">\n",
       "        <span style=\"color:#9ca3af; font-weight:700;font-size:8px; line-height:1;\">▬</span> Neutral\n",
       "      </td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "      <td style=\"\n",
       "          padding:6px 10px;\n",
       "          white-space:nowrap;\n",
       "          text-align:left;\n",
       "      \">\n",
       "        <span style=\"\n",
       "          display:inline-block;\n",
       "          width:10px;\n",
       "          height:10px;\n",
       "          border-radius:50%;\n",
       "          background:#60a5fa;\n",
       "          margin-right:8px;\n",
       "          vertical-align:middle;\n",
       "        \"></span>\n",
       "        <span style=\"vertical-align:middle; font-weight:600;\">\n",
       "          Center Right\n",
       "        </span>\n",
       "      </td>\n",
       "\n",
       "      <td style=\"\n",
       "          padding:6px 10px;\n",
       "          text-align:left;\n",
       "          white-space:nowrap;\n",
       "          color:#2d3748;\n",
       "      \">\n",
       "        <span style=\"color:#9ca3af; font-weight:700;font-size:8px; line-height:1;\">▬</span> Neutral\n",
       "      </td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "      <td style=\"\n",
       "          padding:6px 10px;\n",
       "          white-space:nowrap;\n",
       "          text-align:left;\n",
       "      \">\n",
       "        <span style=\"\n",
       "          display:inline-block;\n",
       "          width:10px;\n",
       "          height:10px;\n",
       "          border-radius:50%;\n",
       "          background:#2563eb;\n",
       "          margin-right:8px;\n",
       "          vertical-align:middle;\n",
       "        \"></span>\n",
       "        <span style=\"vertical-align:middle; font-weight:600;\">\n",
       "          Right\n",
       "        </span>\n",
       "      </td>\n",
       "\n",
       "      <td style=\"\n",
       "          padding:6px 10px;\n",
       "          text-align:left;\n",
       "          white-space:nowrap;\n",
       "          color:#2d3748;\n",
       "      \">\n",
       "        <span style=\"color:#9ca3af; font-weight:700;font-size:8px; line-height:1;\">▬</span> Neutral\n",
       "      </td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "      <td style=\"\n",
       "          padding:6px 10px;\n",
       "          white-space:nowrap;\n",
       "          text-align:left;\n",
       "      \">\n",
       "        <span style=\"\n",
       "          display:inline-block;\n",
       "          width:10px;\n",
       "          height:10px;\n",
       "          border-radius:50%;\n",
       "          background:#1e3a8a;\n",
       "          margin-right:8px;\n",
       "          vertical-align:middle;\n",
       "        \"></span>\n",
       "        <span style=\"vertical-align:middle; font-weight:600;\">\n",
       "          Far Right\n",
       "        </span>\n",
       "      </td>\n",
       "\n",
       "      <td style=\"\n",
       "          padding:6px 10px;\n",
       "          text-align:left;\n",
       "          white-space:nowrap;\n",
       "          color:#2d3748;\n",
       "      \">\n",
       "        <span style=\"color:#9ca3af; font-weight:700;font-size:8px; line-height:1;\">▬</span> Neutral\n",
       "      </td>\n",
       "    </tr>\n",
       "    \n",
       "    </tbody>\n",
       "  </table>\n",
       "\n",
       "  <div style=\"margin-top:10px; font-size:12px; color:#4a5568; line-height:1.35;\">\n",
       "    Tone varies by leaning: <b>Center</b> is most negative, while <b>Left</b> is most positive.\n",
       "  </div>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# -------------------------\n",
    "# 1) Use in-memory DataFrames\n",
    "# -------------------------\n",
    "news_df = final_df.copy()\n",
    "\n",
    "news_df[\"AgeDays\"] = pd.to_numeric(news_df[\"AgeDays\"], errors=\"coerce\")\n",
    "news_df[\"WeightedSentiment\"] = pd.to_numeric(news_df.get(\"WeightedSentiment\"), errors=\"coerce\")\n",
    "\n",
    "last7 = news_df[news_df[\"AgeDays\"].notna() & (news_df[\"AgeDays\"] < 7)].copy()\n",
    "\n",
    "# -------------------------\n",
    "# 2) Normalize Political Leaning -> 7 buckets\n",
    "# -------------------------\n",
    "LEAN_ORDER = [\n",
    "    \"Far Left\",\n",
    "    \"Left\",\n",
    "    \"Center Left\",\n",
    "    \"Center\",\n",
    "    \"Center Right\",\n",
    "    \"Right\",\n",
    "    \"Far Right\",\n",
    "]\n",
    "\n",
    "# Colours\n",
    "LEAN_COLORS = {\n",
    "    \"Far Left\":     \"#7f1d1d\",  # deep red\n",
    "    \"Left\":         \"#ef4444\",\n",
    "    \"Center Left\":  \"#fca5a5\",\n",
    "    \"Center\":       \"#9ca3af\",  # gray\n",
    "    \"Center Right\": \"#60a5fa\",\n",
    "    \"Right\":        \"#2563eb\",\n",
    "    \"Far Right\":    \"#1e3a8a\",  # deep blue\n",
    "}\n",
    "\n",
    "def normalize_leaning(x: str) -> str:\n",
    "    if pd.isna(x):\n",
    "        return \"Center\"\n",
    "    s = str(x).strip().lower()\n",
    "\n",
    "    if s == \"far left\":\n",
    "        return \"Far Left\"\n",
    "    if s == \"left\":\n",
    "        return \"Left\"\n",
    "    if s in (\"center left\", \"centre left\"):\n",
    "        return \"Center Left\"\n",
    "    if s == \"center\":\n",
    "        return \"Center\"\n",
    "    if s in (\"center right\", \"centre right\"):\n",
    "        return \"Center Right\"\n",
    "    if s == \"right\":\n",
    "        return \"Right\"\n",
    "    if s == \"far right\":\n",
    "        return \"Far Right\"\n",
    "    return \"Center\"\n",
    "\n",
    "last7[\"LeanBucket\"] = last7[\"Political Leaning\"].apply(normalize_leaning)\n",
    "\n",
    "# -------------------------\n",
    "# 3) Political leaning distribution (counts + %)\n",
    "# -------------------------\n",
    "counts = last7[\"LeanBucket\"].value_counts().reindex(LEAN_ORDER, fill_value=0)\n",
    "total_n = int(counts.sum())\n",
    "\n",
    "if total_n == 0:\n",
    "    pct = {k: 0 for k in LEAN_ORDER}\n",
    "else:\n",
    "    pct = {k: round(int(counts[k]) / total_n * 100) for k in LEAN_ORDER}\n",
    "\n",
    "# Fix rounding drift so total == 100\n",
    "drift = 100 - sum(pct.values())\n",
    "if drift != 0 and total_n != 0:\n",
    "    biggest = max(pct, key=pct.get)\n",
    "    pct[biggest] += drift\n",
    "\n",
    "# -------------------------\n",
    "# 4) Blindspot = least covered leaning\n",
    "# -------------------------\n",
    "blindspot = min(pct, key=pct.get) if total_n != 0 else \"Center\"\n",
    "blindspot_color = LEAN_COLORS.get(blindspot, \"#9ca3af\")\n",
    "\n",
    "# -------------------------\n",
    "# 5) Sentiment by leaning (avg WeightedSentiment)\n",
    "# -------------------------\n",
    "sent_means = (\n",
    "    last7.groupby(\"LeanBucket\")[\"WeightedSentiment\"]\n",
    "    .mean()\n",
    "    .reindex(LEAN_ORDER)\n",
    ")\n",
    "\n",
    "def sentiment_label(x):\n",
    "    if pd.isna(x):\n",
    "        return \"(No Data)\"\n",
    "    if x <= -0.4:\n",
    "        return \"Strongly Negative\"\n",
    "    if x <= -0.15:\n",
    "        return \"Moderately Negative\"\n",
    "    if x < 0.15:\n",
    "        return \"Neutral\"\n",
    "    if x < 0.4:\n",
    "        return \"Moderately Positive\"\n",
    "    return \"Strongly Positive\"\n",
    "\n",
    "tone_icon = {\n",
    "    \"Strongly Negative\": '<span style=\"color:#b91c1c; font-weight:700; font-size:15px; line-height:1;\">▼</span>',\n",
    "    \"Moderately Negative\": '<span style=\"color:#f97316; font-weight:700;\">▼</span>',\n",
    "    \"Neutral\": '<span style=\"color:#9ca3af; font-weight:700;font-size:8px; line-height:1;\">▬</span>',\n",
    "    \"Moderately Positive\": '<span style=\"color:#eab308; font-weight:700;\">▲</span>',\n",
    "    \"Strongly Positive\": '<span style=\"color:#b91c1c; font-weight:700; font-size:15px; line-height:1;\">▲</span>',\n",
    "    \"No Data\": '<span style=\"color:#9ca3af;\">---</span>',\n",
    "}\n",
    "\n",
    "valid_sent = sent_means.dropna()\n",
    "if len(valid_sent) > 0:\n",
    "    most_negative = valid_sent.idxmin()\n",
    "    most_positive = valid_sent.idxmax()\n",
    "    sentiment_insight = (\n",
    "        f\"Tone varies by leaning: <b>{most_negative}</b> is most negative, \"\n",
    "        f\"while <b>{most_positive}</b> is most positive.\"\n",
    "    )\n",
    "else:\n",
    "    sentiment_insight = \"Tone by leaning: not enough sentiment data to summarize.\"\n",
    "\n",
    "tone_rows_html = \"\"\n",
    "for k in LEAN_ORDER:\n",
    "    mean_val = sent_means.loc[k]\n",
    "    label = sentiment_label(mean_val)\n",
    "    icon = tone_icon.get(label, \"---\")\n",
    "    color = LEAN_COLORS[k]\n",
    "\n",
    "    tone_rows_html += f\"\"\"\n",
    "    <tr>\n",
    "      <td style=\"\n",
    "          padding:6px 10px;\n",
    "          white-space:nowrap;\n",
    "          text-align:left;\n",
    "      \">\n",
    "        <span style=\"\n",
    "          display:inline-block;\n",
    "          width:10px;\n",
    "          height:10px;\n",
    "          border-radius:50%;\n",
    "          background:{color};\n",
    "          margin-right:8px;\n",
    "          vertical-align:middle;\n",
    "        \"></span>\n",
    "        <span style=\"vertical-align:middle; font-weight:600;\">\n",
    "          {k}\n",
    "        </span>\n",
    "      </td>\n",
    "\n",
    "      <td style=\"\n",
    "          padding:6px 10px;\n",
    "          text-align:left;\n",
    "          white-space:nowrap;\n",
    "          color:#2d3748;\n",
    "      \">\n",
    "        {icon} {label}\n",
    "      </td>\n",
    "    </tr>\n",
    "    \"\"\"\n",
    "\n",
    "# -------------------------\n",
    "# 6) Get latest weekly row (topic/summary/rows_used)\n",
    "# -------------------------\n",
    "row = weekly_df.iloc[-1]\n",
    "topic = str(row.get(\"topic\", \"\"))\n",
    "summary = str(row.get(\"summary\", \"\"))\n",
    "rows_used = int(row.get(\"rows_used\", 0))\n",
    "\n",
    "# -------------------------\n",
    "# 7) Build bar + labels HTML (LEFT column)\n",
    "# -------------------------\n",
    "segments_html = \"\".join(\n",
    "    f\"\"\"<div title=\"{k} {pct[k]}%\" style=\"width:{pct[k]}%; background:{LEAN_COLORS[k]};\"></div>\"\"\"\n",
    "    for k in LEAN_ORDER\n",
    ")\n",
    "\n",
    "labels_html = \"\".join(\n",
    "    f\"\"\"\n",
    "    <div style=\"color:{LEAN_COLORS[k]}; font-weight:700; font-size:12px; text-align:center;\">\n",
    "      {k} {pct[k]}%\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    for k in LEAN_ORDER\n",
    ")\n",
    "\n",
    "left_card_html = f\"\"\"\n",
    "  <div style=\"display:flex; align-items:center; gap:10px; margin-bottom:8px;\">\n",
    "    <span style=\"background:{blindspot_color}; color:white; font-weight:700; font-size:12px;\n",
    "                 padding:4px 8px; border-radius:6px;\">\n",
    "      Blindspot\n",
    "    </span>\n",
    "    <span style=\"font-size:12px; color:#4a5568; border:1px solid #e2e8f0; padding:4px 8px; border-radius:999px;\">\n",
    "      {rows_used} Sources\n",
    "    </span>\n",
    "  </div>\n",
    "\n",
    "  <div style=\"font-size:32px; font-weight:800; line-height:1.1; margin:6px 0 10px;\">\n",
    "    {topic}\n",
    "  </div>\n",
    "\n",
    "  <div style=\"font-size:16px; color:#2d3748; line-height:1.5; margin-bottom:14px;\">\n",
    "    {summary}\n",
    "  </div>\n",
    "\n",
    "  <div style=\"height:14px; border-radius:999px; overflow:hidden; display:flex; border:1px solid #e2e8f0;\">\n",
    "    {segments_html}\n",
    "  </div>\n",
    "\n",
    "  <div style=\"display:grid; grid-template-columns: repeat(7, 1fr); gap:6px; margin-top:10px;\">\n",
    "    {labels_html}\n",
    "  </div>\n",
    "\n",
    "  <div style=\"margin-top:10px; font-size:12px; color:#4a5568;\">\n",
    "    Blindspot indicates the least-represented leaning in the last 7 days:\n",
    "    <b style=\"color:{blindspot_color};\">{blindspot}</b>.\n",
    "  </div>\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------\n",
    "# 8) Tone box HTML\n",
    "# -------------------------\n",
    "right_tone_html = f\"\"\"\n",
    "<div style=\"\n",
    "    border:1px solid #e2e8f0;\n",
    "    border-radius:12px;\n",
    "    padding:14px;\n",
    "    background:#fafafa;\n",
    "    position:sticky; top:12px;\n",
    "\">\n",
    "  <div style=\"font-weight:900; font-size:14px; margin-bottom:8px;\">\n",
    "    Tone by Political Leaning\n",
    "  </div>\n",
    "\n",
    "  <table style=\"width:100%; font-size:12px; border-collapse:collapse;\">\n",
    "    <thead>\n",
    "      <tr style=\"color:#4a5568;\">\n",
    "        <th style=\"text-align:left; padding:6px 10px;\">Leaning</th>\n",
    "        <th style=\"text-align:left; padding:6px 10px;\">Tone</th>\n",
    "      </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "      {tone_rows_html}\n",
    "    </tbody>\n",
    "  </table>\n",
    "\n",
    "  <div style=\"margin-top:10px; font-size:12px; color:#4a5568; line-height:1.35;\">\n",
    "    {sentiment_insight}\n",
    "  </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "# -------------------------\n",
    "# 9) Two-column page layout\n",
    "# -------------------------\n",
    "html = f\"\"\"\n",
    "<div style=\"font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial; max-width: 1200px;\">\n",
    "  <div style=\"display:grid; grid-template-columns: 1fr 340px; gap:28px; align-items:start;\">\n",
    "    <div style=\"max-width: 780px;\">\n",
    "      {left_card_html}\n",
    "    </div>\n",
    "    <div>\n",
    "      {right_tone_html}\n",
    "    </div>\n",
    "  </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
